{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afe753ea",
   "metadata": {},
   "source": [
    "# LeetCode 182: Duplicate Emails\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "**Table: Person**\n",
    "\n",
    "| Column Name | Type    |\n",
    "|-------------|---------|\n",
    "| id          | int     |\n",
    "| email       | varchar |\n",
    "\n",
    "`id` is the primary key (column with unique values) for this table.\n",
    "Each row of this table contains an email. The emails will not contain uppercase letters.\n",
    "\n",
    "**Task:**\n",
    "Write a solution to report all the duplicate emails. Note that it's guaranteed that the email field is not NULL.\n",
    "\n",
    "**Example 1:**\n",
    "\n",
    "**Input:**\n",
    "Person table:\n",
    "| id | email   |\n",
    "|----|---------|\n",
    "| 1  | a@b.com |\n",
    "| 2  | c@d.com |\n",
    "| 3  | a@b.com |\n",
    "\n",
    "**Output:**\n",
    "| Email   |\n",
    "|---------|\n",
    "| a@b.com |\n",
    "\n",
    "**Explanation:** a@b.com is repeated two times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708c29fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete. Database ready.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Setup SQLite in-memory database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 2. Helper function to display query results as a Pandas DataFrame\n",
    "def show(query):\n",
    "    return pd.read_sql_query(query, conn)\n",
    "\n",
    "print(\"Environment setup complete. Database ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc8b88",
   "metadata": {},
   "source": [
    "### Schema Description\n",
    "\n",
    "The schema consists of a single table, `Person`.\n",
    "\n",
    "This is a classic \"Flat Table\" often found in User Identity systems or Contact lists.\n",
    "\n",
    "*   **Primary Key (`id`):** This guarantees row uniqueness (technical uniqueness).\n",
    "*   **Business Key (`email`):** In a perfectly normalized system, `email` might be a `UNIQUE` key. However, the existence of this problem implies that **Business Key constraints are missing or violated**.\n",
    "\n",
    "In Data Engineering, this represents a **Data Quality (DQ)** issue. We have \"Technical Uniqueness\" (different IDs) but \"Business Duplication\" (same person/email)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "147900cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'Person' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create the Person table\n",
    "create_table_sql = \"\"\"\n",
    "CREATE TABLE Person (\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    email VARCHAR(255) NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(create_table_sql)\n",
    "conn.commit()\n",
    "print(\"Table 'Person' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9736a6d4",
   "metadata": {},
   "source": [
    "### Sample Data\n",
    "\n",
    "We will populate the database with the example data provided in the LeetCode problem.\n",
    "\n",
    "**Analysis of Data:**\n",
    "*   **Row 1:** a@b.com (First occurrence)\n",
    "*   **Row 2:** c@d.com (Unique)\n",
    "*   **Row 3:** a@b.com (Duplicate of Row 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf274cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data inserted.\n"
     ]
    }
   ],
   "source": [
    "# Insert sample data\n",
    "insert_data_sql = \"\"\"\n",
    "INSERT INTO Person (id, email) VALUES\n",
    "(1, 'a@b.com'),\n",
    "(2, 'c@d.com'),\n",
    "(3, 'a@b.com');\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(insert_data_sql)\n",
    "conn.commit()\n",
    "print(\"Sample data inserted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3eca7",
   "metadata": {},
   "source": [
    "### ðŸŽ“ Lecture: Aggregation, Grouping, and The Order of Operations\n",
    "\n",
    "As a Senior Data Professional, identifying duplicates is 50% of your job in **ETL pipelines** (Extract, Transform, Load). Before loading data into a Production Data Warehouse, you must ensure referential integrity.\n",
    "\n",
    "To solve this, we rely on the **Split-Apply-Combine** strategy, implemented in SQL via `GROUP BY`.\n",
    "\n",
    "#### 1. The Anatomy of Aggregation\n",
    "We cannot check for duplicates by looking at one row at a time. We must look at the **Set** of data.\n",
    "\n",
    "**The Logic Flow:**\n",
    "1.  **Split:** Divide the table into buckets based on the `email` value.\n",
    "2.  **Apply:** Count the number of items in each bucket.\n",
    "3.  **Combine/Filter:** Return only the buckets where the count is $> 1$.\n",
    "\n",
    "#### 2. ASCII Visual: The Grouping Process\n",
    "\n",
    "    STEP 1: Original Table\n",
    "    +----+---------+\n",
    "    | id | email   |\n",
    "    +----+---------+\n",
    "    | 1  | a@b.com |\n",
    "    | 2  | c@d.com |\n",
    "    | 3  | a@b.com |\n",
    "\n",
    "    STEP 2: GROUP BY email (The \"Buckets\")\n",
    "    \n",
    "    Bucket 'a@b.com':  [ {id:1}, {id:3} ]\n",
    "    Bucket 'c@d.com':  [ {id:2} ]\n",
    "\n",
    "    STEP 3: AGGREGATE (Count rows in buckets)\n",
    "    \n",
    "    'a@b.com' -> Count: 2\n",
    "    'c@d.com' -> Count: 1\n",
    "\n",
    "    STEP 4: FILTER (HAVING Count > 1)\n",
    "    \n",
    "    'a@b.com' -> KEEP (2 > 1)\n",
    "    'c@d.com' -> DROP (1 is not > 1)\n",
    "\n",
    "#### 3. WHERE vs. HAVING (Crucial Concept)\n",
    "This is the #1 Interview Question for Junior/Mid SQL roles.\n",
    "\n",
    "*   **`WHERE` clause:** Filters rows *before* they are grouped.\n",
    "    *   *Can we use WHERE?* No. We don't know the count until *after* we group.\n",
    "    *   *Usage:* `WHERE email LIKE '%.com'` (This happens pre-aggregation).\n",
    "*   **`HAVING` clause:** Filters groups *after* aggregation is calculated.\n",
    "    *   *Usage:* `HAVING COUNT(id) > 1`.\n",
    "\n",
    "#### 4. Relational Algebra\n",
    "In theoretical terms, this operation uses the **Grouping Operator** ($\\gamma$).\n",
    "\n",
    "$$ \\sigma_{count > 1} ( \\gamma_{email, COUNT(id)} (Person) ) $$\n",
    "\n",
    "1.  $\\gamma$ (Gamma): Group by email.\n",
    "2.  $\\sigma$ (Sigma): Select/Filter where count > 1.\n",
    "\n",
    "#### 5. Alternative Approach: Self-Join\n",
    "While `GROUP BY` is preferred for performance ($O(N \\log N)$ or $O(N)$ with hashing), you *could* solve this with a self-join.\n",
    "\n",
    "```sql\n",
    "SELECT DISTINCT p1.email\n",
    "FROM Person p1\n",
    "JOIN Person p2\n",
    "  ON p1.email = p2.email  -- Same email\n",
    " AND p1.id != p2.id       -- Different ID (meaning different physical row)\n",
    "\n",
    "\n",
    " ```\n",
    "\n",
    "This logic says: \"Find me a row that matches another row on email, but isn't the same row.\"\n",
    "**Why avoid this?**\n",
    "##### Performance: It can create a huge number of intermediate rows if there are many duplicates (Cartesian explosion within the duplicate set).\n",
    "##### Readability: GROUP BY explicitly states intent (counting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd158c92",
   "metadata": {},
   "source": [
    "### Step-by-Step Reasoning for the Solution\n",
    "\n",
    "We need to extract emails appearing more than once.\n",
    "\n",
    "**Logical Steps:**\n",
    "1.  **Select Column:** We are interested in `email`.\n",
    "2.  **Grouping:** We must group the data by `email` to calculate statistics for each unique address.\n",
    "3.  **Counting:** Inside each group, we count the occurrences. `COUNT(email)` or `COUNT(id)` or `COUNT(*)` all work here since `email` is not NULL.\n",
    "4.  **Filtering:** We only want groups where the count is strictly greater than 1.\n",
    "5.  **Ordering:** The problem states \"Return the result table in any order,\" so no `ORDER BY` is needed.\n",
    "\n",
    "**Drafting the Query:**\n",
    "\n",
    "    SELECT\n",
    "        email\n",
    "    FROM\n",
    "        Person\n",
    "    GROUP BY\n",
    "        email\n",
    "    HAVING\n",
    "        COUNT(email) > 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f96b17a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final SQL Solution\n",
    "final_query = \"\"\"\n",
    "SELECT\n",
    "    email\n",
    "FROM\n",
    "    Person\n",
    "GROUP BY\n",
    "    email\n",
    "HAVING\n",
    "    COUNT(email) > 1;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8c3f72",
   "metadata": {},
   "source": [
    "### Output Verification\n",
    "\n",
    "Let's trace the execution logic:\n",
    "\n",
    "1.  **Group: a@b.com**\n",
    "    *   Rows found: id=1, id=3.\n",
    "    *   Count: 2.\n",
    "    *   Condition `2 > 1`: **True**.\n",
    "    *   Action: Keep.\n",
    "\n",
    "2.  **Group: c@d.com**\n",
    "    *   Rows found: id=2.\n",
    "    *   Count: 1.\n",
    "    *   Condition `1 > 1`: **False**.\n",
    "    *   Action: Discard.\n",
    "\n",
    "**Expected Output:**\n",
    "| Email   |\n",
    "|---------|\n",
    "| a@b.com |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23ce81a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a@b.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     email\n",
       "0  a@b.com"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute and show final results\n",
    "show(final_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb1cd17",
   "metadata": {},
   "source": [
    "### Summary and Key Takeaways\n",
    "\n",
    "1.  **The Pattern:** Finding duplicates is almost always solved with `GROUP BY [column] HAVING COUNT([column]) > 1`. Memorize this pattern.\n",
    "2.  **Execution Order:** Remember that `HAVING` runs after aggregation, while `WHERE` runs before. You cannot filter by a count in a `WHERE` clause.\n",
    "3.  **Data Quality:** In production, simply finding duplicates isn't enough. You usually need to *remove* them. That would require a more complex query (often using Window Functions like `ROW_NUMBER()`) to keep one instance (e.g., the one with the lowest ID) and delete the rest.\n",
    "4.  **Scalability:** Grouping operations are memory-intensive (the database builds a hash table). On massive datasets, ensure your grouping columns are indexed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
